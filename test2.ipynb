{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "dic1 = {\"a\":1, \"b\":2}\n",
    "if \"a\" in dic1:\n",
    "    print(dic1[\"a\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 0, 0, 0, 0], [0, 0, 0, 0, 0]]\n",
      "[[0, 0, 0, 0, 0], [1, 1, 1, 1, 1]]\n"
     ]
    }
   ],
   "source": [
    "n = 1\n",
    "dp = [[0] * 5 for _ in range(n+1)]\n",
    "print(dp)\n",
    "\n",
    "for i in range(5):\n",
    "    dp[1][i] = 1\n",
    "print(dp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_sentence(sentence):\n",
    "    # Tokenize the sentence\n",
    "    tokens = sentence.split()\n",
    "    print(tokens)\n",
    "    # Create a set of unique words\n",
    "    unique_words = set(tokens)\n",
    "\n",
    "    # Assign numbers to unique words\n",
    "    word_to_number = {word: i for i, word in enumerate(unique_words,start=1)}\n",
    "\n",
    "    # Create a list of numbers corresponding to the tokens\n",
    "    token_numbers = [word_to_number[word] for word in tokens]\n",
    "\n",
    "    return token_numbers\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'is', 'a', 'sample', 'sentence', 'to', 'test', 'the', 'tokenization', 'function']\n",
      "[8, 1, 10, 5, 7, 4, 2, 3, 6, 9]\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "sentence = \"This is a sample sentence to test the tokenization function\"\n",
    "token_numbers = tokenize_sentence(sentence)\n",
    "print(token_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 sample\n",
      "2 test\n",
      "3 is\n",
      "4 This\n",
      "5 tokenization\n",
      "6 to\n",
      "7 sentence\n",
      "8 function\n",
      "9 a\n",
      "10 the\n",
      "{1: 'sample', 2: 'test', 3: 'is', 4: 'This', 5: 'tokenization', 6: 'to', 7: 'sentence', 8: 'function', 9: 'a', 10: 'the'}\n"
     ]
    }
   ],
   "source": [
    "sentence = \"This is a sample sentence to test the tokenization function\"\n",
    "list_words = set(sentence.split())\n",
    "dic = {}\n",
    "for index, word in enumerate(list_words, start = 1):\n",
    "    print(f'{index} {word}')\n",
    "    dic[index] = word\n",
    "\n",
    "print(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 sample\n",
      "2 test\n",
      "3 is\n",
      "4 This\n",
      "5 tokenization\n",
      "6 to\n",
      "7 sentence\n",
      "8 function\n",
      "9 a\n",
      "10 the\n"
     ]
    }
   ],
   "source": [
    "sentence = \"This is a sample sentence to test the tokenization function\"\n",
    "list_words = list(set(sentence.split()))\n",
    "\n",
    "for i in range(len(list_words)):\n",
    "    print(i+1, list_words[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['table', 'chair', 'rack', 'shelf']\n"
     ]
    }
   ],
   "source": [
    "furniture = ['table', 'chair', 'rack', 'shelf']\n",
    "\n",
    "print(furniture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rose\n"
     ]
    }
   ],
   "source": [
    "wife = {'name': 'Rose', 'age': 33}\n",
    "print(wife[\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'age': 33,\n",
      " 'eye_color': 'brown',\n",
      " 'hair_color': 'brown',\n",
      " 'has_hair': True,\n",
      " 'height': 1.6,\n",
      " 'name': 'Rose'}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "wife = {'name': 'Rose', 'age': 33, 'has_hair': True, 'hair_color': 'brown', 'height': 1.6, 'eye_color': 'brown'}\n",
    "pprint.pprint(wife)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 1, 'b': 3, 'c': 4}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_a = {'a': 1, 'b': 2}\n",
    "dict_b = {'b': 3, 'c': 4}\n",
    "dict_c = {**dict_a, **dict_b}\n",
    "dict_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pythonProject-NzVrMXGb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
